{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ETL Step 1: Combining CVS Files\n",
        "\n",
        "## Objective\n",
        "Merge the two raw CSV files (**ai_job_dataset.csv** and **ai_job_dataset.csv**) into a single cosnolidated dataset, while handling differences in columns.\n",
        "\n",
        "## Dateset\n",
        "- **ai_job_dataset.csv** - Part 1 (19 columns, no `salary_local`)\n",
        "- **ai_job_dataset1.csv** - Part 2 (20 columns, includes `salary_local`)\n",
        "\n",
        "##  Column Differences\n",
        "- The second file includes an extra column: `salary_local`.\n",
        "\n",
        "##  Process\n",
        "1. Load both CSV files with **pandas**.\n",
        "2. Align their columns by adding any missing columns (like `salary_local`) with `NaN` values in the first dataset.\n",
        "3. Concatenate the datasets into one.\n",
        "4. Save the combined dataset as `ai_jobs_combined.csv`.\n",
        "\n",
        "##  Expected Output\n",
        "- A single CSV file with **all rows from both parts** and **consistent columns**.\n",
        "- Missing values for `salary_local` in the first file are represented as `NaN` for later cleaning in ETL.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Combined dataset saved. Total rows: 30000\n",
            " Final columns: ['job_id', 'job_title', 'salary_usd', 'salary_currency', 'salary_local', 'experience_level', 'employment_type', 'company_location', 'company_size', 'employee_residence', 'remote_ratio', 'required_skills', 'education_required', 'years_experience', 'industry', 'posting_date', 'application_deadline', 'job_description_length', 'benefits_score', 'company_name']\n"
          ]
        }
      ],
      "source": [
        "# Load the dataset\n",
        "df1 = pd.read_csv(\"../data/inputs/raw/ai_job_dataset.csv\")\n",
        "df2 = pd.read_csv(\"../data/inputs/raw/ai_job_dataset1.csv\")\n",
        "\n",
        "# Align the columns of the two dataframes\n",
        "for col in df2.columns:\n",
        "    if col not in df1.columns:\n",
        "        df1[col] = pd.NA # Fill missing columns with NA\n",
        "\n",
        "# Ensure both datasets have same column order\n",
        "df1 = df1[df2.columns]\n",
        "\n",
        "# Concatenate the two datasets\n",
        "combined_df = pd.concat([df1, df2], ignore_index=True)\n",
        "\n",
        "# Save the combined dataset to a new CSV file\n",
        "combined_df.to_csv(\"../data/inputs/raw/ai_job_dataset_combined.csv\", index=False)\n",
        "\n",
        "# Print the shape of the combined dataset\n",
        "print(f\" Combined dataset saved. Total rows: {combined_df.shape[0]}\")\n",
        "print(f\" Final columns: {combined_df.columns.tolist()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ETL Step 2: Handling Missing Values\n",
        "\n",
        "## Objective\n",
        "Identify and handle missing values in the combined dataset (**ai_job_dataset_combined.csv**) to ensure clean and reliable data for analysis.\n",
        "\n",
        "## What We'll Do\n",
        "1. **Load** the combined dataset.\n",
        "2. **Check** for missing values using `isnull()` and `sum()`.\n",
        "3. **Categorize missing values**:\n",
        "   - **Critical columns** (e.g., `job_id`, `job_title`, `salary_usd`) ‚Äì cannot have missing data.\n",
        "   - **Optional columns** (e.g., `salary_local`, `benefits_score`) ‚Äì can be missing and filled logically.\n",
        "4. **Decide on handling strategy**:\n",
        "   - **Drop rows** if critical data is missing.\n",
        "   - **Fill NaNs** for non-critical data (e.g., replace missing `salary_local` with `Not Provided` or median).\n",
        "5. **Save** the cleaned dataset as `ai_jobs_cleaned.csv`.\n",
        "\n",
        "##  Expected Output\n",
        "- Clean dataset with **no missing critical values** and logical handling of optional ones.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the combined dataset\n",
        "df = pd.read_csv('../data/inputs/raw/ai_job_dataset_combined.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "job_id                        0\n",
              "job_title                     0\n",
              "salary_usd                    0\n",
              "salary_currency               0\n",
              "salary_local              15000\n",
              "experience_level              0\n",
              "employment_type               0\n",
              "company_location              0\n",
              "company_size                  0\n",
              "employee_residence            0\n",
              "remote_ratio                  0\n",
              "required_skills               0\n",
              "education_required            0\n",
              "years_experience              0\n",
              "industry                      0\n",
              "posting_date                  0\n",
              "application_deadline          0\n",
              "job_description_length        0\n",
              "benefits_score                0\n",
              "company_name                  0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.isnull().sum()  # Check for missing values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Drop rows with missing critical values\n",
        "critical_cols = [\"job_id\", \"job_title\", \"salary_usd\"]\n",
        "df = df.dropna(subset=critical_cols)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fill missing values  for optional columns\n",
        "df['salary_local'] = df['salary_local'].fillna('Not Provided')\n",
        "df['benefits_score'] = df['benefits_score'].fillna(df['benefits_score'].median())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Handling Missing Values ‚Äì Final Summary\n",
        "\n",
        " **Findings**\n",
        "- Only one column had missing values: `salary_local` (15,000 rows).\n",
        "- All other 19 columns had **0 missing values**.\n",
        "\n",
        " **Action Taken**\n",
        "- We filled missing `salary_local` values with `\"Not Provided\"`.\n",
        "- No rows were dropped since critical columns (`job_id`, `job_title`, `salary_usd`) had no missing data.\n",
        "\n",
        " **Result**\n",
        "- Total rows: **30,000**\n",
        "- Total columns: **20**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ETL Step 3: Data Cleaning\n",
        "\n",
        "##  Objective\n",
        "Ensure the dataset is **clean, standardized, and analysis-ready** by removing inconsistencies and formatting errors.\n",
        "\n",
        "## üîç What We'll Do\n",
        "1. **Standardize column names**\n",
        "   - Make all lowercase\n",
        "   - Replace spaces with underscores\n",
        "\n",
        "2. **Clean text fields**\n",
        "   - Trim extra spaces\n",
        "   - Ensure consistent capitalization for `job_title`, `company_name`, `industry`\n",
        "\n",
        "3. **Validate date columns**\n",
        "   - Convert `posting_date` & `application_deadline` to datetime format\n",
        "\n",
        "4. **Check salary fields**\n",
        "   - Ensure `salary_usd` is numeric\n",
        "   - Keep `salary_local` as string since some values are \"Not Provided\"\n",
        "\n",
        "5. **Save cleaned dataset**\n",
        "   - File name: `ai_jobs_cleaned_v2.csv`\n",
        "\n",
        "##  Expected Output\n",
        "- Dataset with **clean, standardized column names**\n",
        "- Text fields formatted consistently\n",
        "- Dates properly converted\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "job_id                object\n",
              "job_title             object\n",
              "salary_usd             int64\n",
              "salary_currency       object\n",
              "salary_local          object\n",
              "experience_level      object\n",
              "employment_type       object\n",
              "company_location      object\n",
              "company_size          object\n",
              "employee_residence    object\n",
              "dtype: object"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Standardize column names\n",
        "df.columns = df.columns.str.lower().str.replace(' ', '_')\n",
        "\n",
        "# Clean text fields: strip spaces and standardize capitalization\n",
        "text_cols = ['job_title', 'company_name', 'industry']\n",
        "for col in text_cols:\n",
        "    df[col] = df[col].str.strip().str.title()\n",
        "\n",
        "# Validate and convert date columns\n",
        "df[\"posting_date\"] = pd.to_datetime(df[\"posting_date\"], errors='coerce')\n",
        "df[\"application_deadline\"] = pd.to_datetime(df[\"application_deadline\"], errors='coerce')\n",
        "\n",
        "# Ensure salary_usd is numeric\n",
        "df['salary_usd'] = pd.to_numeric(df['salary_usd'], errors='coerce')\n",
        "\n",
        "# Quick check columns and data types\n",
        "df.dtypes.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>job_id</th>\n",
              "      <th>job_title</th>\n",
              "      <th>salary_usd</th>\n",
              "      <th>salary_currency</th>\n",
              "      <th>salary_local</th>\n",
              "      <th>experience_level</th>\n",
              "      <th>employment_type</th>\n",
              "      <th>company_location</th>\n",
              "      <th>company_size</th>\n",
              "      <th>employee_residence</th>\n",
              "      <th>remote_ratio</th>\n",
              "      <th>required_skills</th>\n",
              "      <th>education_required</th>\n",
              "      <th>years_experience</th>\n",
              "      <th>industry</th>\n",
              "      <th>posting_date</th>\n",
              "      <th>application_deadline</th>\n",
              "      <th>job_description_length</th>\n",
              "      <th>benefits_score</th>\n",
              "      <th>company_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AI00001</td>\n",
              "      <td>Ai Research Scientist</td>\n",
              "      <td>90376</td>\n",
              "      <td>USD</td>\n",
              "      <td>Not Provided</td>\n",
              "      <td>SE</td>\n",
              "      <td>CT</td>\n",
              "      <td>China</td>\n",
              "      <td>M</td>\n",
              "      <td>China</td>\n",
              "      <td>50</td>\n",
              "      <td>Tableau, PyTorch, Kubernetes, Linux, NLP</td>\n",
              "      <td>Bachelor</td>\n",
              "      <td>9</td>\n",
              "      <td>Automotive</td>\n",
              "      <td>2024-10-18</td>\n",
              "      <td>2024-11-07</td>\n",
              "      <td>1076</td>\n",
              "      <td>5.9</td>\n",
              "      <td>Smart Analytics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AI00002</td>\n",
              "      <td>Ai Software Engineer</td>\n",
              "      <td>61895</td>\n",
              "      <td>USD</td>\n",
              "      <td>Not Provided</td>\n",
              "      <td>EN</td>\n",
              "      <td>CT</td>\n",
              "      <td>Canada</td>\n",
              "      <td>M</td>\n",
              "      <td>Ireland</td>\n",
              "      <td>100</td>\n",
              "      <td>Deep Learning, AWS, Mathematics, Python, Docker</td>\n",
              "      <td>Master</td>\n",
              "      <td>1</td>\n",
              "      <td>Media</td>\n",
              "      <td>2024-11-20</td>\n",
              "      <td>2025-01-11</td>\n",
              "      <td>1268</td>\n",
              "      <td>5.2</td>\n",
              "      <td>Techcorp Inc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>AI00003</td>\n",
              "      <td>Ai Specialist</td>\n",
              "      <td>152626</td>\n",
              "      <td>USD</td>\n",
              "      <td>Not Provided</td>\n",
              "      <td>MI</td>\n",
              "      <td>FL</td>\n",
              "      <td>Switzerland</td>\n",
              "      <td>L</td>\n",
              "      <td>South Korea</td>\n",
              "      <td>0</td>\n",
              "      <td>Kubernetes, Deep Learning, Java, Hadoop, NLP</td>\n",
              "      <td>Associate</td>\n",
              "      <td>2</td>\n",
              "      <td>Education</td>\n",
              "      <td>2025-03-18</td>\n",
              "      <td>2025-04-07</td>\n",
              "      <td>1974</td>\n",
              "      <td>9.4</td>\n",
              "      <td>Autonomous Tech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>AI00004</td>\n",
              "      <td>Nlp Engineer</td>\n",
              "      <td>80215</td>\n",
              "      <td>USD</td>\n",
              "      <td>Not Provided</td>\n",
              "      <td>SE</td>\n",
              "      <td>FL</td>\n",
              "      <td>India</td>\n",
              "      <td>M</td>\n",
              "      <td>India</td>\n",
              "      <td>50</td>\n",
              "      <td>Scala, SQL, Linux, Python</td>\n",
              "      <td>PhD</td>\n",
              "      <td>7</td>\n",
              "      <td>Consulting</td>\n",
              "      <td>2024-12-23</td>\n",
              "      <td>2025-02-24</td>\n",
              "      <td>1345</td>\n",
              "      <td>8.6</td>\n",
              "      <td>Future Systems</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>AI00005</td>\n",
              "      <td>Ai Consultant</td>\n",
              "      <td>54624</td>\n",
              "      <td>EUR</td>\n",
              "      <td>Not Provided</td>\n",
              "      <td>EN</td>\n",
              "      <td>PT</td>\n",
              "      <td>France</td>\n",
              "      <td>S</td>\n",
              "      <td>Singapore</td>\n",
              "      <td>100</td>\n",
              "      <td>MLOps, Java, Tableau, Python</td>\n",
              "      <td>Master</td>\n",
              "      <td>0</td>\n",
              "      <td>Media</td>\n",
              "      <td>2025-04-15</td>\n",
              "      <td>2025-06-23</td>\n",
              "      <td>1989</td>\n",
              "      <td>6.6</td>\n",
              "      <td>Advanced Robotics</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    job_id              job_title  salary_usd salary_currency  salary_local  \\\n",
              "0  AI00001  Ai Research Scientist       90376             USD  Not Provided   \n",
              "1  AI00002   Ai Software Engineer       61895             USD  Not Provided   \n",
              "2  AI00003          Ai Specialist      152626             USD  Not Provided   \n",
              "3  AI00004           Nlp Engineer       80215             USD  Not Provided   \n",
              "4  AI00005          Ai Consultant       54624             EUR  Not Provided   \n",
              "\n",
              "  experience_level employment_type company_location company_size  \\\n",
              "0               SE              CT            China            M   \n",
              "1               EN              CT           Canada            M   \n",
              "2               MI              FL      Switzerland            L   \n",
              "3               SE              FL            India            M   \n",
              "4               EN              PT           France            S   \n",
              "\n",
              "  employee_residence  remote_ratio  \\\n",
              "0              China            50   \n",
              "1            Ireland           100   \n",
              "2        South Korea             0   \n",
              "3              India            50   \n",
              "4          Singapore           100   \n",
              "\n",
              "                                   required_skills education_required  \\\n",
              "0         Tableau, PyTorch, Kubernetes, Linux, NLP           Bachelor   \n",
              "1  Deep Learning, AWS, Mathematics, Python, Docker             Master   \n",
              "2     Kubernetes, Deep Learning, Java, Hadoop, NLP          Associate   \n",
              "3                        Scala, SQL, Linux, Python                PhD   \n",
              "4                     MLOps, Java, Tableau, Python             Master   \n",
              "\n",
              "   years_experience    industry posting_date application_deadline  \\\n",
              "0                 9  Automotive   2024-10-18           2024-11-07   \n",
              "1                 1       Media   2024-11-20           2025-01-11   \n",
              "2                 2   Education   2025-03-18           2025-04-07   \n",
              "3                 7  Consulting   2024-12-23           2025-02-24   \n",
              "4                 0       Media   2025-04-15           2025-06-23   \n",
              "\n",
              "   job_description_length  benefits_score       company_name  \n",
              "0                    1076             5.9    Smart Analytics  \n",
              "1                    1268             5.2       Techcorp Inc  \n",
              "2                    1974             9.4    Autonomous Tech  \n",
              "3                    1345             8.6     Future Systems  \n",
              "4                    1989             6.6  Advanced Robotics  "
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ETL Step 4: Data Transformation\n",
        "\n",
        "##  Objective\n",
        "Make the dataset analysis-friendly by creating new calculated fields and ensuring all formats are correct.\n",
        "\n",
        "##  Planned Transformations\n",
        "1. **Create `salary_category`**\n",
        "   - Low (< $50,000)\n",
        "   - Mid ($50,000‚Äì100,000)\n",
        "   - High (> $100,000)\n",
        "\n",
        "2. **Create `remote_status`**\n",
        "   - From `remote_ratio`:\n",
        "     - 0 ‚Üí Onsite\n",
        "     - 50 ‚Üí Hybrid\n",
        "     - 100 ‚Üí Fully Remote\n",
        "\n",
        "3. **Extract date parts**\n",
        "   - From `posting_date` ‚Üí new columns: `posting_year`, `posting_month`\n",
        "\n",
        "4. **Reorder columns**\n",
        "   - Place the most important ones (`job_id`, `job_title`, `salary_usd`, `salary_category`, `remote_status`) up front\n",
        "\n",
        "## ‚úÖ Expected Output\n",
        "- A richer dataset with **categorical features** and **date insights**\n",
        "- All fields ready for EDA and dashboarding\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(15000, 20)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check and remove duplicates\n",
        "duplicates = df.duplicated(subset='job_id').sum()\n",
        "if duplicates > 0:\n",
        "    df = df.drop_duplicates(subset='job_id')\n",
        "\n",
        "# Validate salary ranges\n",
        "invalid_salaries = df[(df['salary_usd'] < 1) | (df['salary_usd'] > 1000000)]\n",
        "df = df[(df['salary_usd'] >= 1) & (df['salary_usd'] <= 1000000)]\n",
        "\n",
        "# Validate remote_ratio\n",
        "df[\"remote_ratio\"].unique()\n",
        "\n",
        "# Check categories integrity\n",
        "df[\"salary_currency\"].unique()\n",
        "\n",
        "\n",
        "df.shape"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
